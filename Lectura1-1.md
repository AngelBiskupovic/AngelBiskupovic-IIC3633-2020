# Lectura 1-1: “Item-Based Collaborative Filtering Recommendation Algorithms”

Esta lectura presenta un algoritmo para sistemas recomendadores basados en filtros colaborativos (CF), a diferencia de otros filtros colaborativos que se basan en usuarios, los autores presentaron un modelo que se basado en ítems, esto quiere decir que, en vez de buscar similitudes entre los usuarios, se buscan similitudes entre los ítems. Con el fin de demostrar las ventajas que este enfoque puede tener, primero se hace énfasis en los principales desafíos que se presentan los filtros colaborativos. Luego, se resume el proceso de los filtros colaborativos, mostrando los desafíos que presentan estos cuando son basados en usuarios. Tercero se explica la creación del algoritmo para filtro colaborativo basado en ítems, mostrando paso a paso el proceso, y mostrando los diferentes métodos existentes para cada paso. Finalmente, se hace una evaluación experimental del algoritmo, evaluando primero la sensibilidad de cada uno de los parámetros, para terminar, se compara el rendimiento de este algoritmo con el algoritmo basado en usuario.

Creo que el método diseñado y evaluado en este artículo presenta varias ideas interesantes. Sin embargo, quiero comentar algunos puntos que, en mi opinión, no fueron adecuados. No estoy muy convencido de que el Data set utilizado haya sido el más adecuado, debido que solo consideró usuarios que hayan evaluado 20 o más películas, y eso está un poco alejado de la realidad, yo hubiese seleccionado un Data set más variado, es decir, tanto con usuarios que hayan evaluado muchas películas como con usuarios que no hayan evaluado ninguna, quizás esto no habría tenido un mayor impacto en los resultados finales, pero se habría utilizado un Data set que se ajusta más a la realidad. 

Otro punto, que va relacionado con el anterior, creo que es un poco contradictorio hablar del desafío de “Sparsity” y utilizar Data set que representaba un “sparsity level” (Así se llamó en el artículo) de 0.9369, es decir el 93,69% de las entradas estaban evaluadas por un usuario, y como dije anteriormente, eso se aleja completamente de la realidad.

Un aspecto interesante, fue haber basado las similitudes en ítems y no en usuarios, como se menciona en el texto, los ítems son más estáticos, es decir, tienden a cambiar menos que la cantidad de usuarios, eso combinado con un algoritmo basado en modelos, fue una combinación interesante, y aunque los resultados que se enseñan al final no muestran una gran mejora en rendimiento respecto a un algoritmo basado en usuario, creo que el principal logro de este algoritmo fue obtener ese rendimiento con una cantidad de datos muy pequeña en comparación a los otros métodos.

Sobre las métricas de evaluación, me pareció pertinente el uso del MAE como parámetro. 

Por último, a modo de opinión, mencionar que esta lectura es del año 2001, por lo que quizás ya existen otros métodos, algoritmos y/o modelos que muestran mejoras más relevantes. Por ejemplo, la predicción basada en regresión lineal no mostró grandes mejoras, incluso para cierta cantidad de vecinos, sus resultados eran peores que el modelo user-user. Sin embargo, en el artículo “*Slope One Predictors for Online Rating-Based Collaborative Filtering*” (Año 2005), se hace una comparación sobre las funciones utilizadas en la versión basada en regresión, en la lectura su predictor era de la forma f(x) = ax + b, y como se mostró en los resultados finales no presentó grandes mejoras con respecto a los esquemas basados en memoria. Por otro lado, en este artículo se presenta un predictor de la forma f(x) = x + b que resultó ser competitivo con los esquemas basados en memoria, es decir se encontró un método. Es decir, hoy en día existe un modelo que basa su predicción en algoritmos de regresión, que funciona bastante bien.
