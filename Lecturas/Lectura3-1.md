# Lectura 3-1: “Performance of Recommender Algorithms on Top-N Recommendation Tasks”

El árticulo presenta una métricas basadas en precisión (LLamadas *Recall* y precisión) y su objetivo es probar que no existe relación trivial entre las métricas de error y las métricas de precisión, además proponen una construcción de datasets, donde separan este en dos subconjuntos (T_head y T_long). Para mostrar resultados, utilizan 6 algoritmos basados en colaboración (Algunos con respectivas variaciones), resumiendo la implementación de cada uno de estos, para finalmente hacer la evaluación de cada uno de estos métodos mediante las métricas de precisión.

Sobre el conjunto de test utilizado, se entiende el porque usaron solo datos con valoraciones de 5 estrellas, pero creo, como opinión personal, que hubiese sido interesante mostrar resultados con un conjunto diferente (Con diferentes valoraciones) y hacer una comparación de resultados con estos dos conjuntos.

En cuanto al valor aleatorio seleccionado (1000), ¿Daba alguna garantía utilizar este valor?Es decir, ¿Se garantizaba que ningún (o al menos la mayoría) item que pudiese ser relevante para el usuario quedara fuera? ¿Se hicieron pruebas con otro valor?.

En los datasets utilizados, se mostró la distribución que cada uno de estos tenía, eso hace que el lector se de una idea de con que tipo de datos se esta trabajando. Además creo que se acercaba bastante a la realidad.

La separación del set de test en dos subconjuntos, donde se dejaban los items que más veces han sido evuluados en uno, y en otro los que no han recibido mucha valoración, permitió que se tuviera una mayor perspectiva de como podían afectar el rendimiento (Basado en métricas de precisión) de cada uno de los algoritmos que fueron sujetos a estas pruebas. Obteniendo resultados muy interesantes, como por ejemplo en el caso del subset de los items con mayor cantidad de valoraciones, el modelo no personalizado obtuvo resultados bastante decentes, a pesar de lo que uno esperaria.

Se utilizaron varios métodos para hacer comparaciones, lo que me pareció apropiado. Sin embargo, en alguno de estos métodos no espcefican los parámetros utilizados, por ejemplo, en el caso de "*neighborhood models*" no hablan del k utilizado, tampoco indican si probaron con otros valores de k, lo que quiero decir, ¿Como saber si efectivamente ese era el mejor resultado que podía tener ese modelo?. En este mismo punto, el uso del coseno no normalizado, no quedaba claro los fundamentos en los que se basaron para simplificar la ecuación de predicción de rating. Por otro lado, si hacen referencia al árticulo "*Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model*" de Yehuda Koren, en este se explica con mayor detalle como se llega a esta simplificación. Más aún, en "*Scalable Collaborative Filtering with Jointly Derived NeighborhoodInterpolation Weights*" del mismo Yehuda Koren en conjunto con Robert M. Bell, dan todos los fundamentos teóricos y matemáticos que explican paso a paso, y de manera ordenada, la reducción de la ecuación. 

En cuanto a los resultados obtenidos, un punto interesante, fue el hecho de que a medida de que se movia dentro del set llamado "*longer tail items*" el *accuracy* mejoraba si crecía el número de factores latentes, esto puede ser debido a que a mayor cantidad de factores latentes, mayor es la cantidad de características que se pueden extraer de un item. 
Creo que faltó una comparación en la evaluación de los métodos utilizando conjunto de test completo, de esta manera el lector habría tenido una idea más gráfica de lo conveniente que puede resultar separar el dataset de test. Además, faltó una comparación entre los modelos utilizados con las variaciones implementadas, y con los modelos implementados sin estas, para probar la mejora en resultados.

Como conclusiones de este árticulo, creo que sus principales aportes, fue proponer una construcción más cuidadosa del dataset, y de esta manera evitar resultados que puedan estar "sesgados". Por otro lado, el proponer variaciones en los modelos (como la del Knn mencionada anteriormente en este comentario) comunmente utilizados, y obtener mejoras en los resultados, fue otro aporte importante.